
catchers:
  error-catcher:
    catcher: !!com.btoddb.chronicle.catchers.DirectCallCatcherImpl

  rest-catcher:
    catcher: !!com.btoddb.chronicle.catchers.RestCatcherImpl
      bind: 0.0.0.0
      port: 8083
    snoopers:
      timestamp-snooper: !!com.btoddb.chronicle.snoopers.TimestampSnooper
        headerName: timestamp
        overwrite: true

routers:
  rest-to-hdfs: !!com.btoddb.chronicle.routers.OneToOneRouterImpl
    catcher: rest-catcher
    plunker: hdfs-plunker-avro
  default-route: !!com.btoddb.chronicle.routers.ConditionalRouterImpl
    condition: headers[skipDefaultRouting] = .+ AND body = hello
    plunker: garbage-plunker
  error-route: !!com.btoddb.chronicle.routers.OneToOneRouterImpl
    catcher: error-catcher
    plunker: error-plunker

#
# plunkers
#

plunkers:
  file-plunker:
    plunker: !!com.btoddb.chronicle.plunkers.FilePlunkerImpl
      filePattern: tmp/app/data.out
    fpq:
      maxTransactionSize: 2000
      maxMemorySegmentSizeInBytes: 10000
      maxJournalFileSize: 10000000
      maxJournalDurationInMs: 30000
      flushPeriodInMs: 1000
      numberOfFlushWorkers: 4
      journalDirectory: tmp/chronicle/queues/file-plunker/journals
      pagingDirectory: tmp/chronicle/queues/file-plunker/pages

  hdfs-plunker-text:
    plunker: !!com.btoddb.chronicle.plunkers.HdfsPlunkerImpl
#      pathPattern: hdfs://dn7dmphnn01.dcloud.starwave.com:9000/user/tburruss/chronicle/${header:customer}/${header:timestamp:date}
      pathPattern: tmp/chronicle/hdfs/${header:customer}/${header:timestamp:date}
      permNamePattern: file.json
      openNamePattern: _file.json.tmp
      fileFactory: !!com.btoddb.chronicle.plunkers.hdfs.HdfsTextFileFactoryImpl
        serializer: !!com.btoddb.chronicle.serializers.JsonSerializerImpl

    fpq:
      maxTransactionSize: 2000
      maxMemorySegmentSizeInBytes: 10000
      maxJournalFileSize: 10000000
      maxJournalDurationInMs: 30000
      flushPeriodInMs: 1000
      numberOfFlushWorkers: 4
      journalDirectory: tmp/chronicle/queues/hdfs-plunker/journals
      pagingDirectory: tmp/chronicle/queues/hdfs-plunker/pages

  hdfs-plunker-avro:
    plunker: !!com.btoddb.chronicle.plunkers.HdfsPlunkerImpl
#      pathPattern: hdfs://dn7dmphnn01.dcloud.starwave.com:9000/user/tburruss/chronicle/${header:customer}/${header:timestamp:date}
      pathPattern: tmp/chronicle/hdfs/${header:customer}/${header:timestamp:date}
      permNamePattern: file.avro
      openNamePattern: _file.avro.tmp
      fileFactory: !!com.btoddb.chronicle.plunkers.hdfs.HdfsAvroFileFactoryImpl
        serializer: !!com.btoddb.chronicle.serializers.AvroSerializerImpl
        codecFactory: !!com.btoddb.chronicle.plunkers.hdfs.SnappyCodecFactoryImpl
    fpq:
      maxTransactionSize: 2000
      maxMemorySegmentSizeInBytes: 10000
      maxJournalFileSize: 10000000
      maxJournalDurationInMs: 30000
      flushPeriodInMs: 1000
      numberOfFlushWorkers: 4
      journalDirectory: tmp/chronicle/queues/hdfs-plunker/journals
      pagingDirectory: tmp/chronicle/queues/hdfs-plunker/pages

  error-plunker:
    plunker: !!com.btoddb.chronicle.plunkers.FilePlunkerImpl
      filePattern: tmp/${header:customer}/errors.out
    fpq:
      maxTransactionSize: 2000
      maxMemorySegmentSizeInBytes: 10000
      maxJournalFileSize: 10000000
      maxJournalDurationInMs: 30000
      flushPeriodInMs: 1000
      numberOfFlushWorkers: 4
      journalDirectory: tmp/chronicle/queues/error-plunker/journals
      pagingDirectory: tmp/chronicle/queues/error-plunker/pages

errorHandler: !!com.btoddb.chronicle.ErrorHandlerImpl
  catcher: error-catcher

stopFile: /tmp/chronicle.stop
